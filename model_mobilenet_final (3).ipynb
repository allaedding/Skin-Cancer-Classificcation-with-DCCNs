{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_mobilenet_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9k59v7gDozY",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbLLLk3G20F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c6053152-c34c-4976-be2e-f62d3ac48c08"
      },
      "source": [
        "# download the data\n",
        "!wget https://s3.amazonaws.com/isic-challenge-2019/ISIC_2019_Training_Input.zip\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-03 12:59:44--  https://s3.amazonaws.com/isic-challenge-2019/ISIC_2019_Training_Input.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.229.101\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.229.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9771618190 (9.1G) [application/zip]\n",
            "Saving to: ‘ISIC_2019_Training_Input.zip’\n",
            "\n",
            "ISIC_2019_Training_ 100%[===================>]   9.10G  14.0MB/s    in 11m 18s \n",
            "\n",
            "2019-06-03 13:11:03 (13.7 MB/s) - ‘ISIC_2019_Training_Input.zip’ saved [9771618190/9771618190]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9REv0n6wHHJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c13567f-4c22-4358-c803-b0fde96b472a"
      },
      "source": [
        "#Extract the data\n",
        "#!unzip ISIC_2019_Training_Input.zip\n",
        "\n",
        "import zipfile\n",
        "import time\n",
        "start = time.time()\n",
        "with zipfile.ZipFile(\"ISIC_2019_Training_Input.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(elapsed)  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128.168523311615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwL9KWmwCTF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#delete non images files\n",
        "!rm ISIC_2019_Training_Input/ATTRIBUTION.txt\n",
        "!rm ISIC_2019_Training_Input/LICENSE.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKRdUcxRHVK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5d351637-ad6d-4697-8b82-0b54bf86044b"
      },
      "source": [
        "#import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Read in the data\n",
        "ground_truth = pd.read_csv('https://s3.amazonaws.com/isic-challenge-2019/ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "# Display some information in the dataset\n",
        "ground_truth.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>MEL</th>\n",
              "      <th>NV</th>\n",
              "      <th>BCC</th>\n",
              "      <th>AK</th>\n",
              "      <th>BKL</th>\n",
              "      <th>DF</th>\n",
              "      <th>VASC</th>\n",
              "      <th>SCC</th>\n",
              "      <th>UNK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ISIC_0000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ISIC_0000001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ISIC_0000002</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIC_0000003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ISIC_0000004</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK\n",
              "0  ISIC_0000000  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "1  ISIC_0000001  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "2  ISIC_0000002  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "3  ISIC_0000003  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0\n",
              "4  ISIC_0000004  1.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjR3GP2LEq8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set y as the labels\n",
        "y = []\n",
        "for row in ground_truth.iterrows():\n",
        "    innerlist = []\n",
        "    newlist = row[1].index[row[1].values[1:].argmax() + 1]\n",
        "    y.append(newlist)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6otIz8nGe8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5dHc9eE80iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add a name to the label series\n",
        "yd = pd.Series(y) \n",
        "yd.name = 'cclass'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW5JEaFn95WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzpz7EzG88Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(yd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLZh5WOMEFY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the metadata into training and validation\n",
        "df_train, df_val = train_test_split(ground_truth, test_size=0.2, random_state=101, stratify=yd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9wtoGJ4PFHNa",
        "colab": {}
      },
      "source": [
        "# Get a list of images in each of the two folders\n",
        "folder = os.listdir('ISIC_2019_Training_Input')\n",
        "\n",
        "# Get a list of train and val images\n",
        "#all_list = list(ground_truth['image'])\n",
        "#\n",
        "train_list = list(df_train['image'])\n",
        "val_list = list(df_val['image'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K92hheCEmS-",
        "colab_type": "text"
      },
      "source": [
        "# create a work directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K52lswmOCd0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a work directory\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# Training files directory\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# Validation files directory\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iGgWIf_M-4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create sub directory for the classes\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        dir_path = os.path.join(train_dir, col)\n",
        "        os.mkdir(dir_path)\n",
        "        dir_path = os.path.join(val_dir, col)\n",
        "        os.mkdir(dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7-1bD1NNKGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the directories\n",
        "!ls ./base_dir/train_dir/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oHqtfoZRnx6",
        "colab_type": "text"
      },
      "source": [
        "# Transfer the images into the folders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMYjli7oHhtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer the training images\n",
        "for row in df_train.iterrows():\n",
        "    image = row[1].image\n",
        "    # The argmax error was occuring because the first column (image) is a string.\n",
        "    # By using row[1].values[1:] we skip the first column.  This means we need \n",
        "    # add 1 to get the correct row[1].index.\n",
        "    label = row[1].index[row[1].values[1:].argmax() + 1]\n",
        "    fname = image + '.jpg'\n",
        "\n",
        "    if fname in folder:\n",
        "        # source path to image\n",
        "        src = os.path.join('ISIC_2019_Training_Input', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVVpm0vKRij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer the training images\n",
        "for row in df_val.iterrows():\n",
        "    image = row[1].image\n",
        "    # The argmax error was occuring because the first column (image) is a string.\n",
        "    # By using row[1].values[1:] we skip the first column.  This means we need \n",
        "    # add 1 to get the correct row[1].index.\n",
        "    label = row[1].index[row[1].values[1:].argmax() + 1]\n",
        "    fname = image + '.jpg'\n",
        "\n",
        "    if fname in folder:\n",
        "        # source path to image\n",
        "        src = os.path.join('ISIC_2019_Training_Input', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qIHHjuaGgt5",
        "colab_type": "text"
      },
      "source": [
        "**length of training and validation examples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmku0nkQKXvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2c68d6b8-a503-4b60-e2ee-bdd1ba274d5d"
      },
      "source": [
        "# validation examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(val_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total)        "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MEL 904\n",
            "NV 2575\n",
            "BCC 665\n",
            "AK 173\n",
            "BKL 525\n",
            "DF 48\n",
            "VASC 51\n",
            "SCC 126\n",
            "total =  5067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywkmjix2NMKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d5f1e409-b77b-4aa3-f8f6-6b560cb963f0"
      },
      "source": [
        "# training examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(train_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total)     "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MEL 3618\n",
            "NV 10300\n",
            "BCC 2658\n",
            "AK 694\n",
            "BKL 2099\n",
            "DF 191\n",
            "VASC 202\n",
            "SCC 502\n",
            "total =  20264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVqzL6N9UeE1",
        "colab_type": "text"
      },
      "source": [
        "# Balance the training an validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc_uyRpzre_d",
        "colab_type": "text"
      },
      "source": [
        "## Balancing the train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JxfYP_7rR1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, random\n",
        "mellen = len(os.listdir('base_dir/train_dir/MEL'))\n",
        "nvlen = len(os.listdir('base_dir/train_dir/NV'))\n",
        "for i in range(nvlen - mellen):\n",
        "    file = random.choice(os.listdir(\"base_dir/val_dir/NV\"))\n",
        "    dst = os.path.join(val_dir,'NV', file)\n",
        "    os.remove(dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8wZh_PdrcRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(train_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IItHZ56dGxrL",
        "colab_type": "text"
      },
      "source": [
        "## Balancing the val data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o8sQecpS9NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, random\n",
        "mellen = len(os.listdir('base_dir/val_dir/MEL'))\n",
        "nvlen = len(os.listdir('base_dir/val_dir/NV'))\n",
        "for i in range(nvlen - mellen):\n",
        "    file = random.choice(os.listdir(\"base_dir/val_dir/NV\"))\n",
        "    dst = os.path.join(val_dir,'NV', file)\n",
        "    os.remove(dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILFJ_5sxgL22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1356a7ba-26a4-4ab0-e5e7-0bb4a11555b1"
      },
      "source": [
        "# validation examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(val_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total) \n",
        "val_len = total"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MEL 904\n",
            "NV 904\n",
            "BCC 665\n",
            "AK 173\n",
            "BKL 525\n",
            "DF 48\n",
            "VASC 51\n",
            "SCC 126\n",
            "total =  3396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCG3EibqLXjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deleting UNK class because its empty\n",
        "#!rm -r base_dir/val_dir/UNK\n",
        "#!rm -r base_dir/train_dir/UNK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfDrgh2wRaZC",
        "colab": {}
      },
      "source": [
        "!rm -r aug_dir\n",
        "!rm -r base_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyF76cppseD8",
        "colab_type": "text"
      },
      "source": [
        "## Augment the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Sep4fY5K2d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "# Class 'nv' is not going to be augmented\n",
        "class_list = ['MEL', 'BKL', 'BCC', 'SCC', 'VASC', 'DF', 'AK']\n",
        "#class_list = ['MEL', 'BKL', 'BCC', 'SCC', 'VASC', 'DF', 'AK']\n",
        "for item in class_list:\n",
        "\n",
        "    # Create a temporary directory for the augmented images\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "\n",
        "    # Create a directory within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # List all the images in the directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir\n",
        "    for fname in img_list:\n",
        "        # source path to image\n",
        "        src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(img_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator to augment the images in real time\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        # brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                              save_to_dir=save_path,\n",
        "                                              save_format='jpg',\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "    num_aug_images_wanted = 6000  # total number of images we want to have in each class\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted - num_files) / batch_size))\n",
        "\n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0, num_batches):\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "767cb7d35e301369f020cdbb705da1620ba8e594",
        "id": "NuCKpxG_HzdT",
        "colab_type": "text"
      },
      "source": [
        "**Visualize 50 augmented images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIadymhpByvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import imageio as im\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "5f0e13a8455af926fe449e1b3ea818b704724202",
        "id": "CwD7fvQ0HzdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots images with labels within jupyter notebook\n",
        "# source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n",
        "\n",
        "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "        \n",
        "plots(imgs, titles=None) # titles=labels will display the image labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2XlsvgoSAoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# End of Data Preparation\n",
        "### ===================================================================================== ###\n",
        "# Start of Model Building"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VLJRPNQ0TJU",
        "colab_type": "text"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEr295cT0NDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "\n",
        "\n",
        "from keras.metrics import categorical_crossentropy\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqwZdFq3IKIA",
        "colab_type": "text"
      },
      "source": [
        "## summary on the full model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abSO4kMNBBIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "mobilenet_model = MobileNet(input_shape=(224, 224, 3), include_top=True, weights=\"imagenet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAaoDT7ZBUuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(mobilenet_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuFKxPuUAs2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobilenet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmLMNBUeH3D_",
        "colab_type": "text"
      },
      "source": [
        "## editing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r6SbdmLH116",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3199
        },
        "outputId": "7ecbe2cb-21de-41ef-f301-fc879d1c3339"
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "mobilenet_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "mobilenet_model.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 3s 0us/step\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "=================================================================\n",
            "Total params: 3,228,864\n",
            "Trainable params: 3,206,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLgg7YYN0Xv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The paths for the training and validation images\n",
        "train_path = 'base_dir/train_dir'\n",
        "val_path = 'base_dir/val_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE6IbS2BAu2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare a few useful values\n",
        "num_train_samples = train_len\n",
        "num_val_samples = val_len\n",
        "train_batch_size = 100\n",
        "val_batch_size = 100\n",
        "image_height = 224\n",
        "image_width = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqpeps8PAw7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare how many steps are needed in an iteration\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amPyTb8aFTM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "985a59a3-34f8-48b4-e9f6-dfdd29ea2d4c"
      },
      "source": [
        "# Set up generators\n",
        "\n",
        "datagenr = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "    keras.applications.mobilenet.preprocess_input)\n",
        "\n",
        "\n",
        "train_batches = datagenr.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=train_batch_size)\n",
        "\n",
        "val_batches = datagenr.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=val_batch_size)\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_batches = datagenr.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=False)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 30228 images belonging to 8 classes.\n",
            "Found 3396 images belonging to 8 classes.\n",
            "Found 3396 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f35-uLrrAzj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN6zTtHDC_DD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4353370d-63dc-43e7-c042-78bbb0c9a72f"
      },
      "source": [
        "#get the last layer shape\n",
        "last_layer = mobilenet_model.get_layer('conv_pw_13_relu')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape: (None, 7, 7, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eHHE6XSC_oD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "#x = layers.GlobalAveragePooling2D()(last_output)\n",
        "x = layers.GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 1024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(8, activation='softmax')(x)\n",
        "# Configure and compile the model\n",
        "model = Model(mobilenet_model.input, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnUhC14ndKrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze the weights of the layers that we aren't training (training the last 23)\n",
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp8roWfnc-_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j38kdRKI-yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfxKrNqFPeog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOT74FDYFhe2",
        "colab_type": "text"
      },
      "source": [
        "# Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAb0ExxKDGia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('models')\n",
        "import time\n",
        "start = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCd8mRRYE3VW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1295
        },
        "outputId": "c654ec31-b3d7-42d0-e206-69c8e529992a"
      },
      "source": [
        "# Declare the filepath for the saved model\n",
        "\n",
        "#filepath=\"models/model-{epoch:02d}-{categorical_accuracy:.2f}-{val_categorical_accuracy:.2f}.h5\"\n",
        "filepath=\"models/mobile-{epoch:02d}-{val_categorical_accuracy:.2f}.h5\"\n",
        "\n",
        "\n",
        "# Declare a checkpoint to save the best version of the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# Reduce the learning rate as the learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                             # class_weight=class_weights,\n",
        "                              validation_data=val_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=30,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks_list)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "303/303 [==============================] - 472s 2s/step - loss: 1.8284 - categorical_accuracy: 0.5284 - val_loss: 2.3968 - val_categorical_accuracy: 0.3260\n",
            "\n",
            "Epoch 00001: val_categorical_accuracy improved from -inf to 0.32597, saving model to models/mobile-01-0.33.h5\n",
            "Epoch 2/30\n",
            "303/303 [==============================] - 439s 1s/step - loss: 1.0535 - categorical_accuracy: 0.6274 - val_loss: 2.1232 - val_categorical_accuracy: 0.3934\n",
            "\n",
            "Epoch 00002: val_categorical_accuracy improved from 0.32597 to 0.39340, saving model to models/mobile-02-0.39.h5\n",
            "Epoch 3/30\n",
            "303/303 [==============================] - 444s 1s/step - loss: 0.9059 - categorical_accuracy: 0.6798 - val_loss: 2.1042 - val_categorical_accuracy: 0.3802\n",
            "\n",
            "Epoch 00003: val_categorical_accuracy did not improve from 0.39340\n",
            "Epoch 4/30\n",
            "303/303 [==============================] - 438s 1s/step - loss: 0.7906 - categorical_accuracy: 0.7157 - val_loss: 2.0628 - val_categorical_accuracy: 0.4049\n",
            "\n",
            "Epoch 00004: val_categorical_accuracy improved from 0.39340 to 0.40489, saving model to models/mobile-04-0.40.h5\n",
            "Epoch 5/30\n",
            "303/303 [==============================] - 435s 1s/step - loss: 0.7118 - categorical_accuracy: 0.7430 - val_loss: 1.6984 - val_categorical_accuracy: 0.4585\n",
            "\n",
            "Epoch 00005: val_categorical_accuracy improved from 0.40489 to 0.45848, saving model to models/mobile-05-0.46.h5\n",
            "Epoch 6/30\n",
            "303/303 [==============================] - 431s 1s/step - loss: 0.6188 - categorical_accuracy: 0.7751 - val_loss: 1.8989 - val_categorical_accuracy: 0.4149\n",
            "\n",
            "Epoch 00006: val_categorical_accuracy did not improve from 0.45848\n",
            "Epoch 7/30\n",
            "303/303 [==============================] - 431s 1s/step - loss: 0.5409 - categorical_accuracy: 0.8042 - val_loss: 1.8121 - val_categorical_accuracy: 0.4729\n",
            "\n",
            "Epoch 00007: val_categorical_accuracy improved from 0.45848 to 0.47291, saving model to models/mobile-07-0.47.h5\n",
            "Epoch 8/30\n",
            "303/303 [==============================] - 437s 1s/step - loss: 0.4675 - categorical_accuracy: 0.8316 - val_loss: 2.0068 - val_categorical_accuracy: 0.4429\n",
            "\n",
            "Epoch 00008: val_categorical_accuracy did not improve from 0.47291\n",
            "Epoch 9/30\n",
            "303/303 [==============================] - 430s 1s/step - loss: 0.3978 - categorical_accuracy: 0.8567 - val_loss: 2.4238 - val_categorical_accuracy: 0.4237\n",
            "\n",
            "Epoch 00009: val_categorical_accuracy did not improve from 0.47291\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "Epoch 10/30\n",
            "303/303 [==============================] - 428s 1s/step - loss: 0.2952 - categorical_accuracy: 0.8958 - val_loss: 2.3460 - val_categorical_accuracy: 0.4346\n",
            "\n",
            "Epoch 00010: val_categorical_accuracy did not improve from 0.47291\n",
            "Epoch 11/30\n",
            "303/303 [==============================] - 429s 1s/step - loss: 0.2496 - categorical_accuracy: 0.9146 - val_loss: 2.5649 - val_categorical_accuracy: 0.4373\n",
            "\n",
            "Epoch 00011: val_categorical_accuracy did not improve from 0.47291\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "Epoch 12/30\n",
            "303/303 [==============================] - 434s 1s/step - loss: 0.2066 - categorical_accuracy: 0.9320 - val_loss: 2.5021 - val_categorical_accuracy: 0.4405\n",
            "\n",
            "Epoch 00012: val_categorical_accuracy did not improve from 0.47291\n",
            "Epoch 13/30\n",
            "303/303 [==============================] - 430s 1s/step - loss: 0.1867 - categorical_accuracy: 0.9385 - val_loss: 2.5401 - val_categorical_accuracy: 0.4408\n",
            "\n",
            "Epoch 00013: val_categorical_accuracy did not improve from 0.47291\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "Epoch 14/30\n",
            "303/303 [==============================] - 429s 1s/step - loss: 0.1687 - categorical_accuracy: 0.9478 - val_loss: 2.5659 - val_categorical_accuracy: 0.4379\n",
            "\n",
            "Epoch 00014: val_categorical_accuracy did not improve from 0.47291\n",
            "Epoch 15/30\n",
            "303/303 [==============================] - 433s 1s/step - loss: 0.1613 - categorical_accuracy: 0.9495 - val_loss: 2.6550 - val_categorical_accuracy: 0.4346\n",
            "\n",
            "Epoch 00015: val_categorical_accuracy did not improve from 0.47291\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 16/30\n",
            "303/303 [==============================] - 437s 1s/step - loss: 0.1554 - categorical_accuracy: 0.9523 - val_loss: 2.8715 - val_categorical_accuracy: 0.4181\n",
            "\n",
            "Epoch 00016: val_categorical_accuracy did not improve from 0.47291\n",
            "Epoch 17/30\n",
            "235/303 [======================>.......] - ETA: 1:27 - loss: 0.1484 - categorical_accuracy: 0.9559"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLxXDoqBRFBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(elapsed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgfAmj5e3M4",
        "colab_type": "text"
      },
      "source": [
        "# Model testing and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXF4Nihhdh-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_cat_acc = \\\n",
        "model.evaluate_generator(val_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U53bolDldmJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation of the best epoch\n",
        "model.load_weights('models/mobile-08-0.61.h5')\n",
        "\n",
        "\n",
        "#val_loss, val_cat_acc = \\\n",
        "model.evaluate_generator(val_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae6UmsfHdpnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a confusion matrix of the test images\n",
        "test_labels = val_batches.classes\n",
        "# Make predictions\n",
        "predictions = model.predict_generator(val_batches, steps=val_steps, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UYuIw5LF4Zc",
        "colab_type": "text"
      },
      "source": [
        "**Training and validation loss per epoch curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYYW9WJzdyJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve a list of accuracy results on training and test data\n",
        "# sets for each training epoch\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, label = \"training\")\n",
        "plt.plot(epochs, val_acc, label = \"validation\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, label = \"training\")\n",
        "plt.plot(epochs, val_loss, label = \"validation\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI4QWZCzFv4E",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYdlX_Jd4oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare a function for plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
        "\n",
        "cm_plot_labels = ['MEL', 'BKL', 'BCC', 'SCC', 'VASC', 'DF', 'AK', 'NV']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoQ6EIYtd5k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKXExWseWlY",
        "colab_type": "text"
      },
      "source": [
        "# Upload the model to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkvHEnJC9-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'models/model-30-1.00-0.97.h5' -d 'Densenet-model-0.97.h5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAvby2or13nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelname = 'Densenet-model-0.97.h5'\n",
        "modelweight = 'Densenet-model-0.97_weightbest.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKSkz4_-C961",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apyL3-xRC93S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZeAcuiYC9xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Save Keras Model or weights on google drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# create on Colab directory\n",
        "model.save(modelname)    \n",
        "model_file = drive.CreateFile({'title' : modelname})\n",
        "model_file.SetContentFile(modelname)\n",
        "model_file.Upload()\n",
        "\n",
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjJzvdT5Dy9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(modelweight)\n",
        "weights_file = drive.CreateFile({'title' : modelweight})\n",
        "weights_file.SetContentFile(modelweight)\n",
        "weights_file.Upload()\n",
        "drive.CreateFile({'id': weights_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bg5Tks3auCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXHy3VyT4_M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/drive/My\\ Drive/densenet89.h5' -d ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URZcsHxV4ljF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv 'Densenet-model-0.97.h5' 'content/drive/My Drive/densenetmodels/Densenet-model-0.97.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q4ma4yf0kbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('drive/My Drive/densenetmodels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2YZjl5KFrtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad9KnkHXnzBu",
        "colab_type": "text"
      },
      "source": [
        "# Experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89vsLC49GZ1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r base_dir/train_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA-LrqUqoffi",
        "colab_type": "text"
      },
      "source": [
        "**resizing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYAho5hZp3G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r base_dir/train_dir2\n",
        "!rm -r base_dir/train_dir3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4MtCkmlowY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AFpgLhkFroo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training file directory\n",
        "train_dir2 = os.path.join(base_dir, 'train_dir2')\n",
        "os.mkdir(train_dir2)\n",
        "\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        dir_path = os.path.join(train_dir2, col)\n",
        "        os.mkdir(dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xag7TOUISDDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resizing all images in train dir\n",
        "width = 448\n",
        "train_fld = os.listdir (train_dir)\n",
        "for subfld in train_fld:\n",
        "    class_dir = os.path.join(train_dir,subfld)\n",
        "    dst_class_dir = os.path.join(train_dir2,subfld)\n",
        "    temp_img = os.listdir (class_dir)    \n",
        "    if '.ipynb_checkpoints' in temp_img:\n",
        "        temp_img.remove('.ipynb_checkpoints')\n",
        "        !rm -r temp_img +'.ipynb_checkpoints' \n",
        "    for nb in range((int(len(temp_img)))):\n",
        "        im=cv2.imread(class_dir + '/' + temp_img[nb])\n",
        "        img=cv2.resize(im,(width,width)) \n",
        "        iname =os.path.join(dst_class_dir,str(nb) +'resized448.jpg')\n",
        "        cv2.imwrite(iname, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj8sV_0GpVa9",
        "colab_type": "text"
      },
      "source": [
        "**slicing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kZHDoARqqYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training file directory\n",
        "train_dir3 = os.path.join(base_dir, 'train_dir3')\n",
        "os.mkdir(train_dir3)\n",
        "\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        dir_path = os.path.join(train_dir3, col)\n",
        "        os.mkdir(dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypjEvYRWtHSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install image_slicer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3XmHtLLpX32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# slicing one image to 4 blocks the result is 5 images\n",
        "import image_slicer\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "train_fld = os.listdir (train_dir2)\n",
        "for subfld in train_fld:\n",
        "  if subfld != 'NV':\n",
        "      class_dir = os.path.join(train_dir2,subfld)\n",
        "      dst_class_dir = os.path.join(train_dir3,subfld)\n",
        "      temp_img = os.listdir (class_dir)\n",
        "      if '.ipynb_checkpoints' in temp_img:\n",
        "          temp_img.remove('.ipynb_checkpoints')\n",
        "      for nb in range((int(len(temp_img)))):\n",
        "          image_slicer.slice(class_dir +'/'+ temp_img[nb], 4)\n",
        "          #shutil.move(class_dir +'/'+ temp_img[nb] , dst_class_dir +'/'+ temp_img[nb] )\n",
        "          #delete the original images\n",
        "          original_img = class_dir +'/'+ temp_img[nb]\n",
        "          os.remove(original_img) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_S_k0r3ozyM",
        "colab_type": "text"
      },
      "source": [
        "**shuffling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGe2AJhSpSyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, random\n",
        "train_fld = os.listdir (train_dir2)\n",
        "for subfld in train_fld:\n",
        "    class_dir = os.path.join(train_dir2,subfld)\n",
        "    temp_img = os.listdir (class_dir)\n",
        "    if subfld != 'NV':\n",
        "        for nb in range((int(len(temp_img)))):\n",
        "            file = random.choice(temp_img)\n",
        "            src = os.path.join(class_dir, file)\n",
        "            dst = os.path.join(class_dir, str(nb) + '_shuffl.jpg')\n",
        "            shutil.move(src ,dst)\n",
        "            temp_img.remove(str(file)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQDMzl6kyAz1",
        "colab_type": "text"
      },
      "source": [
        "**combining to base_dir**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTxcHljLyDAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# combain 4 images to one with the same size\n",
        "\n",
        "def concat_tile(im_list_2d):\n",
        "    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])\n",
        "  \n",
        "train_fld = os.listdir (train_dir2)\n",
        "for subfld in train_fld:\n",
        "  if subfld != 'NV':\n",
        "      class_dir = os.path.join(train_dir2,subfld)\n",
        "      dst_class_dir = os.path.join(train_dir,subfld)\n",
        "      temp_img = os.listdir (class_dir)\n",
        "      if '.ipynb_checkpoints' in temp_img:\n",
        "          temp_img.remove('.ipynb_checkpoints')\n",
        "      mod = len(temp_img) % 4\n",
        "      for dl in range(mod):\n",
        "          del temp_img[0]\n",
        "      for nb in range((int(len(temp_img)/4))):\n",
        "          im1 = cv2.imread(class_dir +'/'+ temp_img[0])\n",
        "          im2 = cv2.imread(class_dir +'/'+ temp_img[1])\n",
        "          im3 = cv2.imread(class_dir +'/'+ temp_img[2])\n",
        "          im4 = cv2.imread(class_dir +'/'+ temp_img[3])\n",
        "          im1_s = cv2.resize(im1, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "          im2_s = cv2.resize(im2, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "          im3_s = cv2.resize(im3, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "          im4_s = cv2.resize(im4, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "          im_tile = concat_tile([[im1_s, im2_s],[im3_s, im4_s]])\n",
        "          iname =os.path.join(dst_class_dir,str(nb) +'final.jpg') \n",
        "          cv2.imwrite(iname, im_tile)\n",
        "          del temp_img[:4]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUN0DvQPzp7U",
        "colab_type": "text"
      },
      "source": [
        "**gathering done**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVX3Vnwr0q2T",
        "colab_type": "text"
      },
      "source": [
        "**resizing original in train_dir3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mo3XfU02W3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#resizing all images in train dir\n",
        "width = 224\n",
        "train_fld = os.listdir (train_dir)\n",
        "for subfld in train_fld:\n",
        "    class_dir = os.path.join(train_dir3,subfld)\n",
        "    dst_class_dir = os.path.join(train_dir,subfld)\n",
        "    temp_img = os.listdir (class_dir)    \n",
        "    if '.ipynb_checkpoints' in temp_img:\n",
        "        temp_img.remove('.ipynb_checkpoints')\n",
        "        !rm -r temp_img +'.ipynb_checkpoints' \n",
        "    for nb in range((int(len(temp_img)))):\n",
        "        im=cv2.imread(class_dir + '/' + temp_img[nb])\n",
        "        img=cv2.resize(im,(width,width)) \n",
        "        iname =os.path.join(dst_class_dir,str(nb) +'resize224.jpg')\n",
        "        cv2.imwrite(iname, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYDfcNdUzxFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#moving files from scr to dst\n",
        "import os, random\n",
        "train_fld = os.listdir (train_dir3)\n",
        "for subfld in train_fld:\n",
        "    class_dir = os.path.join(train_dir3,subfld)\n",
        "    \n",
        "    temp_img = os.listdir (class_dir)\n",
        "    for nb in range((int(len(temp_img)))):\n",
        "        src = os.path.join(class_dir, file)\n",
        "        dst = os.path.join(os.path.join(train_dir1,subfld),file)\n",
        "        shutil.move(src , dst )\n",
        "        temp_img.remove(str(file))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrw7DEs-2c1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting files by extension\n",
        "import os\n",
        "\n",
        "test = os.listdir(train_dir3)\n",
        "\n",
        "for item in test:\n",
        "    if item.endswith(\".jpg\"):\n",
        "        os.remove(os.path.join(train_dir3, item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgq0g9e54dry",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "80e7c14e-02ba-458d-865e-eaba01e3b6b6"
      },
      "source": [
        "# training examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(train_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total) \n",
        "train_len = total"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MEL 7236\n",
            "NV 10300\n",
            "BCC 5316\n",
            "AK 1388\n",
            "BKL 4198\n",
            "DF 382\n",
            "VASC 404\n",
            "SCC 1004\n",
            "total =  30228\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}