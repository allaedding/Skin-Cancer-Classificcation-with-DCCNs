{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9k59v7gDozY",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbLLLk3G20F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the data\n",
        "!wget https://s3.amazonaws.com/isic-challenge-2019/ISIC_2019_Training_Input.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9REv0n6wHHJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract the data\n",
        "#!unzip ISIC_2019_Training_Input.zip\n",
        "\n",
        "import zipfile\n",
        "import time\n",
        "start = time.time()\n",
        "with zipfile.ZipFile(\"ISIC_2019_Training_Input.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(elapsed)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwL9KWmwCTF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#delete non images files\n",
        "!rm ISIC_2019_Training_Input/ATTRIBUTION.txt\n",
        "!rm ISIC_2019_Training_Input/LICENSE.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKRdUcxRHVK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Read in the data\n",
        "ground_truth = pd.read_csv('https://s3.amazonaws.com/isic-challenge-2019/ISIC_2019_Training_GroundTruth.csv')\n",
        "\n",
        "# Display some information in the dataset\n",
        "ground_truth.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjR3GP2LEq8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set y as the labels\n",
        "y = []\n",
        "for row in ground_truth.iterrows():\n",
        "    innerlist = []\n",
        "    newlist = row[1].index[row[1].values[1:].argmax() + 1]\n",
        "    y.append(newlist)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6otIz8nGe8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5dHc9eE80iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add a name to the label series\n",
        "yd = pd.Series(y) \n",
        "yd.name = 'cclass'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YW5JEaFn95WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzpz7EzG88Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(yd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLZh5WOMEFY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the metadata into training and validation\n",
        "df_train, df_val = train_test_split(ground_truth, test_size=0.2, random_state=101, stratify=yd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9wtoGJ4PFHNa",
        "colab": {}
      },
      "source": [
        "# Get a list of images in each of the two folders\n",
        "folder = os.listdir('ISIC_2019_Training_Input')\n",
        "\n",
        "# Get a list of train and val images\n",
        "#all_list = list(ground_truth['image'])\n",
        "#\n",
        "train_list = list(df_train['image'])\n",
        "val_list = list(df_val['image'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K92hheCEmS-",
        "colab_type": "text"
      },
      "source": [
        "# create a work directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K52lswmOCd0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a work directory\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# Training files directory\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# Validation files directory\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iGgWIf_M-4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create sub directory for the classes\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        dir_path = os.path.join(train_dir, col)\n",
        "        os.mkdir(dir_path)\n",
        "        dir_path = os.path.join(val_dir, col)\n",
        "        os.mkdir(dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7-1bD1NNKGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check the directories\n",
        "!ls ./base_dir/train_dir/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oHqtfoZRnx6",
        "colab_type": "text"
      },
      "source": [
        "# Transfer the images into the folders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMYjli7oHhtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer the training images\n",
        "for row in df_train.iterrows():\n",
        "    image = row[1].image\n",
        "    # The argmax error was occuring because the first column (image) is a string.\n",
        "    # By using row[1].values[1:] we skip the first column.  This means we need \n",
        "    # add 1 to get the correct row[1].index.\n",
        "    label = row[1].index[row[1].values[1:].argmax() + 1]\n",
        "    fname = image + '.jpg'\n",
        "\n",
        "    if fname in folder:\n",
        "        # source path to image\n",
        "        src = os.path.join('ISIC_2019_Training_Input', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVVpm0vKRij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transfer the training images\n",
        "for row in df_val.iterrows():\n",
        "    image = row[1].image\n",
        "    # The argmax error was occuring because the first column (image) is a string.\n",
        "    # By using row[1].values[1:] we skip the first column.  This means we need \n",
        "    # add 1 to get the correct row[1].index.\n",
        "    label = row[1].index[row[1].values[1:].argmax() + 1]\n",
        "    fname = image + '.jpg'\n",
        "\n",
        "    if fname in folder:\n",
        "        # source path to image\n",
        "        src = os.path.join('ISIC_2019_Training_Input', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qIHHjuaGgt5",
        "colab_type": "text"
      },
      "source": [
        "**length of training and validation examples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmku0nkQKXvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(val_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywkmjix2NMKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training examples\n",
        "total = 0\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        npath = os.path.join(train_dir, col)\n",
        "        print(col,len(os.listdir(npath)))\n",
        "        total = total+len(os.listdir(npath))\n",
        "print('total = ',total)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVqzL6N9UeE1",
        "colab_type": "text"
      },
      "source": [
        "# Balance the training an validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IItHZ56dGxrL",
        "colab_type": "text"
      },
      "source": [
        "## Balancing the val data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o8sQecpS9NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import os, random\n",
        "#mellen = len(os.listdir('base_dir/val_dir/MEL'))\n",
        "#nvlen = len(os.listdir('base_dir/val_dir/NV'))\n",
        "#for i in range(nvlen - mellen):\n",
        "#    file = random.choice(os.listdir(\"base_dir/val_dir/NV\"))\n",
        "#    dst = os.path.join(val_dir,'NV', file)\n",
        "#    os.remove(dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCG3EibqLXjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deleting UNK class because its empty\n",
        "!rm -r base_dir/val_dir/UNK\n",
        "!rm -r base_dir/train_dir/UNK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XfDrgh2wRaZC",
        "colab": {}
      },
      "source": [
        "#!rm -r aug_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyF76cppseD8",
        "colab_type": "text"
      },
      "source": [
        "## Augment the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Sep4fY5K2d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "# Class 'nv' is not going to be augmented\n",
        "class_list = ['MEL', 'BKL', 'BCC', 'SCC', 'VASC', 'DF', 'AK']\n",
        "\n",
        "for item in class_list:\n",
        "\n",
        "    # Create a temporary directory for the augmented images\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "\n",
        "    # Create a directory within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # List all the images in the directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir\n",
        "    for fname in img_list:\n",
        "        # source path to image\n",
        "        src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(img_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator to augment the images in real time\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        # brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                              save_to_dir=save_path,\n",
        "                                              save_format='jpg',\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "    num_aug_images_wanted = 6000  # total number of images we want to have in each class\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted - num_files) / batch_size))\n",
        "\n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0, num_batches):\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "767cb7d35e301369f020cdbb705da1620ba8e594",
        "id": "NuCKpxG_HzdT",
        "colab_type": "text"
      },
      "source": [
        "**Visualize 50 augmented images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIadymhpByvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import imageio as im\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "5f0e13a8455af926fe449e1b3ea818b704724202",
        "id": "CwD7fvQ0HzdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots images with labels within jupyter notebook\n",
        "# source: https://github.com/smileservices/keras_utils/blob/master/utils.py\n",
        "\n",
        "def plots(ims, figsize=(12,6), rows=5, interp=False, titles=None): # 12,6\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "        \n",
        "plots(imgs, titles=None) # titles=labels will display the image labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2XlsvgoSAoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# End of Data Preparation\n",
        "### ===================================================================================== ###\n",
        "# Start of Model Building"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VLJRPNQ0TJU",
        "colab_type": "text"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEr295cT0NDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the libraries\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "\n",
        "\n",
        "from keras.metrics import categorical_crossentropy\n",
        "\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqwZdFq3IKIA",
        "colab_type": "text"
      },
      "source": [
        "## summary on the full model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abSO4kMNBBIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "mobilenet_model = MobileNet(input_shape=(224, 224, 3), include_top=True, weights=\"imagenet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAaoDT7ZBUuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(mobilenet_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuFKxPuUAs2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobilenet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmLMNBUeH3D_",
        "colab_type": "text"
      },
      "source": [
        "## editing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r6SbdmLH116",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
        "mobilenet_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "mobilenet_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLgg7YYN0Xv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The paths for the training and validation images\n",
        "train_path = 'base_dir/train_dir'\n",
        "val_path = 'base_dir/val_dir'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE6IbS2BAu2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare a few useful values\n",
        "num_train_samples = len(df_train)\n",
        "num_val_samples = len(df_val)\n",
        "train_batch_size = 100\n",
        "val_batch_size = 100\n",
        "image_height = 224\n",
        "image_width = 224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqpeps8PAw7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare how many steps are needed in an iteration\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amPyTb8aFTM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up generators\n",
        "\n",
        "datagenr = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "    keras.applications.mobilenet.preprocess_input)\n",
        "\n",
        "\n",
        "train_batches = datagenr.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=train_batch_size)\n",
        "\n",
        "val_batches = datagenr.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=val_batch_size)\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_batches = datagenr.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f35-uLrrAzj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Freeze the weights of the layers that we aren't training (training the last 23)\n",
        "for layer in mobilenet_model.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN6zTtHDC_DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the last layer shape\n",
        "last_layer = mobilenet_model.get_layer('conv_pw_13_relu')\n",
        "print('last layer output shape:', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eHHE6XSC_oD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.GlobalMaxPooling2D()(last_output)\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(8, activation='softmax')(x)\n",
        "# Configure and compile the model\n",
        "model = Model(mobilenet_model.input, x)\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j38kdRKI-yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfxKrNqFPeog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOT74FDYFhe2",
        "colab_type": "text"
      },
      "source": [
        "# Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAb0ExxKDGia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('models')\n",
        "import time\n",
        "start = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCd8mRRYE3VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare the filepath for the saved model\n",
        "\n",
        "#filepath=\"models/model-{epoch:02d}-{categorical_accuracy:.2f}-{val_categorical_accuracy:.2f}.h5\"\n",
        "filepath=\"models/mobile-{epoch:02d}-{val_categorical_accuracy:.2f}.h5\"\n",
        "\n",
        "\n",
        "# Declare a checkpoint to save the best version of the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# Reduce the learning rate as the learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                             # class_weight=class_weights,\n",
        "                              validation_data=val_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=10,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks_list)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLxXDoqBRFBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "end = time.time()\n",
        "elapsed = end - start\n",
        "print(elapsed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFgfAmj5e3M4",
        "colab_type": "text"
      },
      "source": [
        "# Model testing and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXF4Nihhdh-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_cat_acc = \\\n",
        "model.evaluate_generator(val_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U53bolDldmJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation of the best epoch\n",
        "model.load_weights('models/mobile-08-0.61.h5')\n",
        "\n",
        "\n",
        "#val_loss, val_cat_acc = \\\n",
        "model.evaluate_generator(val_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae6UmsfHdpnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a confusion matrix of the test images\n",
        "test_labels = val_batches.classes\n",
        "# Make predictions\n",
        "predictions = model.predict_generator(val_batches, steps=val_steps, verbose=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UYuIw5LF4Zc",
        "colab_type": "text"
      },
      "source": [
        "**Training and validation loss per epoch curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYYW9WJzdyJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrieve a list of accuracy results on training and test data\n",
        "# sets for each training epoch\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, label = \"training\")\n",
        "plt.plot(epochs, val_acc, label = \"validation\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot(epochs, loss, label = \"training\")\n",
        "plt.plot(epochs, val_loss, label = \"validation\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title('Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI4QWZCzFv4E",
        "colab_type": "text"
      },
      "source": [
        "**Confusion matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYdlX_Jd4oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare a function for plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
        "\n",
        "cm_plot_labels = ['MEL', 'BKL', 'BCC', 'SCC', 'VASC', 'DF', 'AK', 'NV']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoQ6EIYtd5k6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoKXExWseWlY",
        "colab_type": "text"
      },
      "source": [
        "# Upload the model to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkvHEnJC9-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp 'models/model-30-1.00-0.97.h5' -d 'Densenet-model-0.97.h5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAvby2or13nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelname = 'Densenet-model-0.97.h5'\n",
        "modelweight = 'Densenet-model-0.97_weightbest.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKSkz4_-C961",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apyL3-xRC93S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZeAcuiYC9xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. Save Keras Model or weights on google drive\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# create on Colab directory\n",
        "model.save(modelname)    \n",
        "model_file = drive.CreateFile({'title' : modelname})\n",
        "model_file.SetContentFile(modelname)\n",
        "model_file.Upload()\n",
        "\n",
        "# download to google drive\n",
        "drive.CreateFile({'id': model_file.get('id')})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjJzvdT5Dy9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(modelweight)\n",
        "weights_file = drive.CreateFile({'title' : modelweight})\n",
        "weights_file.SetContentFile(modelweight)\n",
        "weights_file.Upload()\n",
        "drive.CreateFile({'id': weights_file.get('id')})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bg5Tks3auCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXHy3VyT4_M3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/drive/My\\ Drive/densenet89.h5' -d ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URZcsHxV4ljF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv 'Densenet-model-0.97.h5' 'content/drive/My Drive/densenetmodels/Densenet-model-0.97.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q4ma4yf0kbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir('drive/My Drive/densenetmodels')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2YZjl5KFrtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89vsLC49GZ1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AFpgLhkFroo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training file directory\n",
        "train_dir2 = os.path.join(base_dir, 'train_dir2')\n",
        "os.mkdir(train_dir2)\n",
        "\n",
        "for col in ground_truth.columns:\n",
        "    if not (col == 'image' or  col == 'UNK'):\n",
        "        dir_path = os.path.join(train_dir2, col)\n",
        "        os.mkdir(dir_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvG5C_BzsyKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def concat_tile(im_list_2d):\n",
        "    return cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in im_list_2d])\n",
        "  \n",
        "train_fld = os.listdir (train_dir2)\n",
        "for subfld in train_fld:\n",
        "    class_dir = os.path.join(train_dir,subfld)\n",
        "    dst_class_dir = os.path.join(train_dir2,subfld)\n",
        "    temp_img = os.listdir (class_dir)\n",
        "    if '.ipynb_checkpoints' in temp_img:\n",
        "        temp_img.remove('.ipynb_checkpoints')\n",
        "    for nb in range((int(len(temp_img)/4))):\n",
        "        im1 = cv2.imread('base_dir/train_dir/'+subfld+'/'+temp_img[0])\n",
        "        im2 = cv2.imread('base_dir/train_dir/'+subfld+'/'+temp_img[1])\n",
        "        im3 = cv2.imread('base_dir/train_dir/'+subfld+'/'+temp_img[2])\n",
        "        im4 = cv2.imread('base_dir/train_dir/'+subfld+'/'+temp_img[3])\n",
        "        \n",
        "        im_tile = concat_tile([[im1, im2],[im3, im4]])\n",
        "        iname =os.path.join(dst_class_dir,str(nb) +'.jpg') \n",
        "        cv2.imwrite(iname, im_tile)\n",
        "        del temp_img[:4]\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVCjf3zeF3Gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(im1.shape)\n",
        "print(im2.shape) \n",
        "print(im3.shape) \n",
        "print(im4.shape) \n",
        "print('base_dir/train_dir/'+subfld+'/'+temp_img[0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}